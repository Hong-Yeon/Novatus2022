{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"!pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:05:03.259246Z","iopub.execute_input":"2022-07-12T09:05:03.259729Z","iopub.status.idle":"2022-07-12T09:05:12.454184Z","shell.execute_reply.started":"2022-07-12T09:05:03.259675Z","shell.execute_reply":"2022-07-12T09:05:12.452999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport math\n\nimport keras_tuner as kt\nfrom keras_tuner.tuners import Hyperband\n\nimport IPython\n\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import GRU, Dropout, Dense, Conv1D\nfrom keras.utils.vis_utils import plot_model\n\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom scipy.signal import savgol_filter\nfrom scipy.ndimage.interpolation import shift\n\nfrom xgboost import XGBRegressor, plot_importance \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error\n\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:05:12.457015Z","iopub.execute_input":"2022-07-12T09:05:12.457703Z","iopub.status.idle":"2022-07-12T09:05:12.466610Z","shell.execute_reply.started":"2022-07-12T09:05:12.457663Z","shell.execute_reply":"2022-07-12T09:05:12.465522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"data_train1 = pd.read_excel('../input/heat-def/DVF5000_SPD_Spectrum1_Steel.xlsx', sheet_name = 'Sheet1' )    \ndata_train2 = pd.read_excel('../input/thermal-disp23-spindle/DVF5000_SPD_Spectrum2_Steel.xlsx', sheet_name = 'Sheet1' )    \ndata_train3 = pd.read_excel('../input/thermal-disp23-spindle/DVF5000_SPD_Spectrum3_Steel.xlsx', sheet_name = 'Sheet1' )    ","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:05:12.468073Z","iopub.execute_input":"2022-07-12T09:05:12.468501Z","iopub.status.idle":"2022-07-12T09:07:20.495913Z","shell.execute_reply.started":"2022-07-12T09:05:12.468461Z","shell.execute_reply":"2022-07-12T09:07:20.494824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Error data 제거를 위한 Slicing\nSlice_value = 300\ndata_train1 = data_train1.iloc[Slice_value:-Slice_value,:]\ndata_train2 = data_train2.iloc[Slice_value:-Slice_value,:]\ndata_train3 = data_train3.iloc[Slice_value:-Slice_value,:]","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:20.498683Z","iopub.execute_input":"2022-07-12T09:07:20.499242Z","iopub.status.idle":"2022-07-12T09:07:20.505854Z","shell.execute_reply.started":"2022-07-12T09:07:20.499191Z","shell.execute_reply":"2022-07-12T09:07:20.504495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.concat([data_train1,data_train2,data_train3], ignore_index = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:20.507358Z","iopub.execute_input":"2022-07-12T09:07:20.507884Z","iopub.status.idle":"2022-07-12T09:07:20.597972Z","shell.execute_reply.started":"2022-07-12T09:07:20.507837Z","shell.execute_reply":"2022-07-12T09:07:20.596885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## 불필요한 column 제거","metadata":{}},{"cell_type":"code","source":"data_train = data_train.drop(columns = ['SCAN', 'Day', 'Time'])","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:20.607329Z","iopub.execute_input":"2022-07-12T09:07:20.608059Z","iopub.status.idle":"2022-07-12T09:07:20.696454Z","shell.execute_reply.started":"2022-07-12T09:07:20.608020Z","shell.execute_reply":"2022-07-12T09:07:20.695551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Sensor_index = 2\nif Sensor_index == 2:\n    pd_raw_X = data_train[['H1', 'S2', 'S3', 'S4', 'S5', 'S6', 'X_Motor', 'Y_Motor', 'Z_Motor',\n        'SPD_Motor', 'X_Servo', 'X_Screw_BRG','SPD_RPM', 'Z_Servo',\n        'Y_Servo', 'Y_Screw_BRG', 'Z_Screw_BRG', 'Column_Rear',\n        'Saddle_Rear', 'Bed_Mid', 'C_Axis_Gear', 'C_Axis_BRG', 'Air_Upper',\n        'Air_Lower', 'Machine_Room_Air', 'Cooler_Outler_Supply',\n        'Cooler_Inlet_Return']]\nelif Sensor_index == 1:\n    pd_raw_X = data_train[['H1', 'S2', 'S3', 'S4', 'S5', 'S6']]\nelif Sensor_index == 3:\n    pd_raw_X = data_train[['H1', 'SPD_RPM', 'X_Servo', 'X_Screw_BRG', 'Z_Servo']]\n    \npd_raw_Y = data_train.filter(like = 'DISP')\n\npd_raw_X_columns = pd_raw_X.columns\npd_raw_Y_columns = pd_raw_Y.columns","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:20.697649Z","iopub.execute_input":"2022-07-12T09:07:20.697958Z","iopub.status.idle":"2022-07-12T09:07:20.721845Z","shell.execute_reply.started":"2022-07-12T09:07:20.697931Z","shell.execute_reply":"2022-07-12T09:07:20.720602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_slicing_index = []\ndata_slicing_index.append(0)\ndata_slicing_index.append(data_train1.shape[0])\ndata_slicing_index.append(data_train2.shape[0])\ndata_slicing_index.append(data_train.shape[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Boolean 집합\nSmoothing_Curve = 0 ##Moving Average 적용 = 1, 미적용 = 0\nTime_Split_Boolean = 0 ##Sampling rate 변경 적용 = 1, 미적용 = 0\nScale_Boolean = 1 ##Scaler 적용 = 1, 미적용 = 0\nTD_Boolean = 0 ## Timedistributed 적용 = 1, 미적용 = 0\nCv_Boolean = 0 ## Conv1D 적용 = 1, 미적용 = 0\nSavgol_Boolean = 1 ##사비츠키 골레이 필터 적용 =1 , 미적용 = 0","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:20.723588Z","iopub.execute_input":"2022-07-12T09:07:20.725655Z","iopub.status.idle":"2022-07-12T09:07:20.730406Z","shell.execute_reply.started":"2022-07-12T09:07:20.725617Z","shell.execute_reply":"2022-07-12T09:07:20.729633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#raise SystemExit(\"Exit from script\")\n\n#sys.exit(\"Exit from script\")","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:20.802110Z","iopub.execute_input":"2022-07-12T09:07:20.803167Z","iopub.status.idle":"2022-07-12T09:07:20.807754Z","shell.execute_reply.started":"2022-07-12T09:07:20.803114Z","shell.execute_reply":"2022-07-12T09:07:20.806657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Moving Average","metadata":{}},{"cell_type":"code","source":"##Smoothing_Curve 0 = None\n##Smoothing_Curve 1 = Moving Average 적용 (Default)\nif Smoothing_Curve == 1:\n    \n    Window_Size = 59 ##하기의 M에 해당, 홀수로 설정하여야 계산 용이\n    \n    def Moving_Average(Target_Dataframe,Window_Size): ##Target Array = Dataframe 형태\n        Window_array = np.ones(Window_Size)*float(1/Window_Size)\n        Smooth_Sensor = np.zeros((Target_Dataframe.shape[0]-Window_Size+1,Target_Dataframe.shape[1]))\n        for i in range(Target_Dataframe.shape[1]):\n            ##Target_Array.iloc[:,i] = savgol_filter(Target_Array.iloc[:,i],59,3) Window안의 회귀모형 FIlter, 성능은 좋으나 Computation 과하게 소모, Length 확인 필요\n            y_smooth = np.convolve(Target_Dataframe.iloc[:,i],Window_array) ## N + M - 1개 array 반환\n            y_smooth = shift(y_smooth,Window_Size-1) ## N + M - 1개 array에서 뒤의 (M-1)개 절단\n            y_smooth = y_smooth[2*(Window_Size-1):] ## N + M - 1개 array에서 앞쪽 (M-1)개 절단, total 2*(M-1)개 절단\n            Smooth_Sensor[:,i] = y_smooth ## Sensor 길이 N에서 N-M+1개로 바뀜\n        Smooth_Sensor = pd.DataFrame(Smooth_Sensor, columns = Target_Dataframe.columns)    \n        return Smooth_Sensor\n\n    pd_raw_X = Moving_Average(pd_raw_X,Window_Size)\n    pd_raw_Y = Moving_Average(pd_raw_Y,Window_Size)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:20.808935Z","iopub.execute_input":"2022-07-12T09:07:20.809261Z","iopub.status.idle":"2022-07-12T09:07:20.822848Z","shell.execute_reply.started":"2022-07-12T09:07:20.809233Z","shell.execute_reply":"2022-07-12T09:07:20.821647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Savgol_filter","metadata":{}},{"cell_type":"code","source":"if Savgol_Boolean == 1:   \n    for i in range(pd_raw_Y.shape[1]):\n        pd_raw_Y.iloc[:,i] = savgol_filter(pd_raw_Y.iloc[:,i], 1801, 5)\n    for i in range(pd_raw_X.shape[1]):\n        pd_raw_X.iloc[:,i] = savgol_filter(pd_raw_X.iloc[:,i], 1801, 5)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:20.825154Z","iopub.execute_input":"2022-07-12T09:07:20.826101Z","iopub.status.idle":"2022-07-12T09:07:44.641131Z","shell.execute_reply.started":"2022-07-12T09:07:20.826058Z","shell.execute_reply":"2022-07-12T09:07:44.640364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Time_Split","metadata":{}},{"cell_type":"code","source":"#Sampling 단위 변경\nif Time_Split_Boolean == 1:\n    \n    time_stride = 60\n    \n    def Time_split_Data(Dataframe,time_stride):\n        Quote , remainder = divmod(Dataframe.shape[0],time_stride)\n        split_data = np.zeros((Quote,Dataframe.shape[1]))\n        for i in range(Quote):\n            split_data[i,:] = Dataframe.iloc[time_stride*i,:]\n        return pd.DataFrame(split_data) \n    \n    pd_raw_X = Time_split_Data(pd_raw_X,time_stride)\n    pd_raw_Y = Time_split_Data(pd_raw_Y,time_stride)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:44.642248Z","iopub.execute_input":"2022-07-12T09:07:44.643178Z","iopub.status.idle":"2022-07-12T09:07:44.651067Z","shell.execute_reply.started":"2022-07-12T09:07:44.643112Z","shell.execute_reply":"2022-07-12T09:07:44.650126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,10))\nfor i in range(pd_raw_X.shape[1]):\n    plt.plot(pd_raw_X.iloc[:,i], label = pd_raw_X.columns[i])\nplt.legend(bbox_to_anchor=(1.0, 1.0))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:44.652740Z","iopub.execute_input":"2022-07-12T09:07:44.654053Z","iopub.status.idle":"2022-07-12T09:07:48.994527Z","shell.execute_reply.started":"2022-07-12T09:07:44.653990Z","shell.execute_reply":"2022-07-12T09:07:48.993479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,10))\nfor i in range(pd_raw_Y.shape[1]-1):\n    plt.plot(pd_raw_Y.iloc[:,i], label = pd_raw_Y.columns[i])\nplt.legend(bbox_to_anchor=(1.0, 1.0))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:48.995903Z","iopub.execute_input":"2022-07-12T09:07:48.996478Z","iopub.status.idle":"2022-07-12T09:07:49.772910Z","shell.execute_reply.started":"2022-07-12T09:07:48.996436Z","shell.execute_reply":"2022-07-12T09:07:49.769677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scaling","metadata":{}},{"cell_type":"code","source":"#Scaler 적용\nif Scale_Boolean == 1:\n    #X_Scaler = MinMaxScaler()\n    #Y_Scaler = MinMaxScaler()\n    X_Scaler = StandardScaler()\n    Y_Scaler = StandardScaler()\n    pd_raw_X = pd.DataFrame( X_Scaler.fit_transform(pd_raw_X) )\n    pd_raw_Y = pd.DataFrame( Y_Scaler.fit_transform(pd_raw_Y) )\n    X_std = X_Scaler.scale_\n    Y_std = Y_Scaler.scale_\n    X_mean = X_Scaler.mean_\n    Y_mean = Y_Scaler.mean_","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:49.774282Z","iopub.execute_input":"2022-07-12T09:07:49.774659Z","iopub.status.idle":"2022-07-12T09:07:49.954852Z","shell.execute_reply.started":"2022-07-12T09:07:49.774628Z","shell.execute_reply":"2022-07-12T09:07:49.953843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,10))\nfor i in range(pd_raw_X.shape[1]):\n    plt.plot(pd_raw_X.iloc[:,i], label = pd_raw_X.columns[i])\nplt.legend(bbox_to_anchor=(1.0, 1.0))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:49.956216Z","iopub.execute_input":"2022-07-12T09:07:49.956602Z","iopub.status.idle":"2022-07-12T09:07:54.503799Z","shell.execute_reply.started":"2022-07-12T09:07:49.956531Z","shell.execute_reply":"2022-07-12T09:07:54.502890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,10))\nfor i in range(pd_raw_Y.shape[1]-1):\n    plt.plot(pd_raw_Y.iloc[:,i], label = pd_raw_Y.columns[i])\nplt.legend(bbox_to_anchor=(1.0, 1.0))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:54.505140Z","iopub.execute_input":"2022-07-12T09:07:54.505454Z","iopub.status.idle":"2022-07-12T09:07:55.270907Z","shell.execute_reply.started":"2022-07-12T09:07:54.505427Z","shell.execute_reply":"2022-07-12T09:07:55.269960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sliding Window(Batch 형태로 변환)","metadata":{}},{"cell_type":"code","source":"def sliding_window(X, Y, n_steps, time, stride = 1, time_distributed = 0):\n        \n    # 1. X, Y time delta에 따라 나누기\n    if time > 0:\n        X = X[:-time]\n        Y = Y[time:]\n    elif time == 0:\n        pass\n    \n    # 2. 결과로 낼 x, y\n    result_X = np.array([X[0:n_steps].values])\n    \n    if time_distributed == 1:\n        result_Y = np.array([Y[0:n_steps].values])\n    else: \n        result_Y = np.array([Y[n_steps-1:n_steps].values])\n\n    # 3. step과 stride에 맞춰서 concat, time_distributed 값에 따라 다르게 Y 만들기\n    \n    if time_distributed == 1:\n        for i in tqdm(range(1, X.shape[0]),total=math.trunc(((len(X)-(n_steps-1)-1)/stride))):\n            if i * stride + n_steps > X.shape[0]:\n                #print(\"Data set finish\") # add\n                break\n            result_X = np.concatenate((result_X, [X[i*stride: i*stride+n_steps].values]))\n            result_Y = np.concatenate((result_Y, [Y[i*stride: i*stride+n_steps].values]))\n            \n    else:\n        for i in tqdm(range(1, X.shape[0]),total=math.trunc(((len(X)-(n_steps-1)-1)/stride))):\n            if i * stride + n_steps > X.shape[0]:\n                #print(\"Data set finish\") # add\n                break\n            result_X = np.concatenate((result_X, [X[i*stride: i*stride+n_steps].values]))\n            result_Y = np.concatenate((result_Y, [Y[i*stride+n_steps-1: i*stride+n_steps].values]))\n\n    return result_X, result_Y","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:55.272488Z","iopub.execute_input":"2022-07-12T09:07:55.272873Z","iopub.status.idle":"2022-07-12T09:07:55.282679Z","shell.execute_reply.started":"2022-07-12T09:07:55.272839Z","shell.execute_reply":"2022-07-12T09:07:55.281973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#raise SystemExit(\"Exit from script\")\n\n#sys.exit(\"Exit from script\")","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:55.283852Z","iopub.execute_input":"2022-07-12T09:07:55.284528Z","iopub.status.idle":"2022-07-12T09:07:55.302301Z","shell.execute_reply.started":"2022-07-12T09:07:55.284491Z","shell.execute_reply":"2022-07-12T09:07:55.298794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Batch화 하기","metadata":{}},{"cell_type":"code","source":"def Batch_Input(one_pd_X,one_pd_Y,Time_Split_Boolean):\n    box_size = int(one_pd_X.shape[0]/10) #들어온 데이터셋 10개 박스로 분할\n    \n    if Time_Split_Boolean == 1:\n        n_steps = 30\n        batch_stride = 1\n        time_lag = 0 \n\n    split_X,split_Y = sliding_window(X=one_pd_X, Y=one_pd_Y, n_steps=box_size, time=time_lag, stride=box_size, time_distributed=1)\n    after_sliding_X_T, after_sliding_X_V, after_sliding_Y_T, after_sliding_Y_V = train_test_split(split_X, split_Y, test_size=0.3, random_state=11, shuffle=True)\n        \n    Big_split_X_T = pd.DataFrame(after_sliding_X_T[0,:])\n    Big_split_Y_T = pd.DataFrame(after_sliding_Y_T[0,:])\n    split_X_T,split_Y_T = sliding_window(X=Big_split_X_T, Y=Big_split_Y_T, n_steps=n_steps, time=time_lag, stride=batch_stride, time_distributed=0)   \n\n    Small_Train_X = np.zeros((split_X_T.shape[0]*after_sliding_X_T.shape[0],split_X_T.shape[1],split_X_T.shape[2]))\n    Small_Train_Y = np.zeros((split_Y_T.shape[0]*after_sliding_Y_T.shape[0],split_Y_T.shape[1],split_Y_T.shape[2]))\n    Small_Valid_X = np.zeros((split_X_T.shape[0]*after_sliding_X_V.shape[0],split_X_T.shape[1],split_X_T.shape[2]))\n    Small_Valid_Y = np.zeros((split_Y_T.shape[0]*after_sliding_Y_V.shape[0],split_Y_T.shape[1],split_Y_T.shape[2]))\n    \n    for i in range(after_sliding_X_T.shape[0]):\n        Big_split_X_T = pd.DataFrame(after_sliding_X_T[i,:])\n        Big_split_Y_T = pd.DataFrame(after_sliding_Y_T[i,:])\n        split_X_T,split_Y_T = sliding_window(X=Big_split_X_T, Y=Big_split_Y_T, n_steps=n_steps, time=time_lag, stride=batch_stride, time_distributed=0)\n        Small_Train_X = np.concatenate((Small_Train_X,split_X_T), axis = 0)\n        Small_Train_Y = np.concatenate((Small_Train_Y,split_Y_T), axis = 0)\n    for i in range(after_sliding_X_V.shape[0]):\n        Big_split_X_V = pd.DataFrame(after_sliding_X_V[i,:])\n        Big_split_Y_V = pd.DataFrame(after_sliding_Y_V[i,:])\n        split_X_V,split_Y_V = sliding_window(X=Big_split_X_V, Y=Big_split_Y_V, n_steps=n_steps, time=time_lag, stride=batch_stride, time_distributed=0)\n        Small_Valid_X = np.concatenate((Small_Valid_X,split_X_V), axis = 0)\n        Small_Valid_Y = np.concatenate((Small_Valid_Y,split_Y_V), axis = 0)\n    \n    ##ML용 Data Set 생성\n    ML_pd_raw_X_T = after_sliding_X_T.reshape(-1,after_sliding_X_T.shape[2])\n    ML_pd_raw_Y_T = after_sliding_Y_T.reshape(-1,after_sliding_Y_T.shape[2])\n    ML_pd_raw_X_V = after_sliding_X_V.reshape(-1,after_sliding_X_V.shape[2])\n    ML_pd_raw_Y_V = after_sliding_Y_V.reshape(-1,after_sliding_Y_V.shape[2])\n\n    return Small_Train_X,Small_Train_Y,Small_Valid_X,Small_Valid_Y,ML_pd_raw_X_T,ML_pd_raw_Y_T,ML_pd_raw_X_V,ML_pd_raw_Y_V","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:55.303791Z","iopub.execute_input":"2022-07-12T09:07:55.304356Z","iopub.status.idle":"2022-07-12T09:07:55.318156Z","shell.execute_reply.started":"2022-07-12T09:07:55.304321Z","shell.execute_reply":"2022-07-12T09:07:55.317119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_X_T1,split_Y_T1,split_X_V1,split_Y_V1,ML_pd_raw_X_T1,ML_pd_raw_Y_T1,ML_pd_raw_X_V1,ML_pd_raw_Y_V1 \\\n= Batch_Input(pd_raw_X.iloc[data_slicing_index[0]:data_slicing_index[1],:],pd_raw_Y.iloc[data_slicing_index[0]:data_slicing_index[1],:],Time_Split_Boolean)\nsplit_X_T2,split_Y_T2,split_X_V2,split_Y_V2,ML_pd_raw_X_T2,ML_pd_raw_Y_T2,ML_pd_raw_X_V2,ML_pd_raw_Y_V2 \\\n= Batch_Input(pd_raw_X.iloc[data_slicing_index[1]:data_slicing_index[2],:],pd_raw_Y.iloc[data_slicing_index[1]:data_slicing_index[2],:],Time_Split_Boolean)\nsplit_X_T3,split_Y_T3,split_X_V3,split_Y_V3,ML_pd_raw_X_T3,ML_pd_raw_Y_T3,ML_pd_raw_X_V3,ML_pd_raw_Y_V3 \\\n= Batch_Input(pd_raw_X.iloc[data_slicing_index[2]:data_slicing_index[3],:],pd_raw_Y.iloc[data_slicing_index[2]:data_slicing_index[3],:],Time_Split_Boolean)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:55.319776Z","iopub.execute_input":"2022-07-12T09:07:55.320438Z","iopub.status.idle":"2022-07-12T09:09:06.315867Z","shell.execute_reply.started":"2022-07-12T09:07:55.320387Z","shell.execute_reply":"2022-07-12T09:09:06.314805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_X = np.concatenate((split_X_T1,split_X_T2,split_X_T3), axis = 0)\nTrain_Y = np.concatenate((split_Y_T1,split_Y_T2,split_Y_T3), axis = 0)\nValid_X = np.concatenate((split_X_V1,split_X_V2,split_X_V3), axis = 0)\nValid_Y = np.concatenate((split_Y_V1,split_Y_V2,split_Y_V3), axis = 0)\nML_pd_raw_X_T = pd.DataFrame( np.concatenate((ML_pd_raw_X_T1,ML_pd_raw_X_T2,ML_pd_raw_X_T3), axis = 0) , columns = pd_raw_X_columns)\nML_pd_raw_Y_T = pd.DataFrame( np.concatenate((ML_pd_raw_Y_T1,ML_pd_raw_Y_T2,ML_pd_raw_Y_T3), axis = 0) , columns = pd_raw_Y_columns)\nML_pd_raw_X_V = pd.DataFrame( np.concatenate((ML_pd_raw_X_V1,ML_pd_raw_X_V2,ML_pd_raw_X_V3), axis = 0) , columns = pd_raw_X_columns)\nML_pd_raw_Y_V = pd.DataFrame( np.concatenate((ML_pd_raw_Y_V1,ML_pd_raw_Y_V2,ML_pd_raw_Y_V3), axis = 0) , columns = pd_raw_Y_columns)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:09:06.317236Z","iopub.execute_input":"2022-07-12T09:09:06.317530Z","iopub.status.idle":"2022-07-12T09:09:07.678514Z","shell.execute_reply.started":"2022-07-12T09:09:06.317504Z","shell.execute_reply":"2022-07-12T09:09:07.677460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GRU Layer","metadata":{}},{"cell_type":"code","source":"input_length = pd_raw_X.shape[1]","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:09:07.679957Z","iopub.execute_input":"2022-07-12T09:09:07.680289Z","iopub.status.idle":"2022-07-12T09:09:07.684887Z","shell.execute_reply.started":"2022-07-12T09:09:07.680260Z","shell.execute_reply":"2022-07-12T09:09:07.683812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ClearTrainingOutput(tf.keras.callbacks.Callback):\n    def on_train_end(*args, **kwargs):\n        IPython.display.clear_output(wait = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:09:07.686589Z","iopub.execute_input":"2022-07-12T09:09:07.687031Z","iopub.status.idle":"2022-07-12T09:09:07.697359Z","shell.execute_reply.started":"2022-07-12T09:09:07.686987Z","shell.execute_reply":"2022-07-12T09:09:07.696377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For Keras Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"def model_builder(hp):\n    model = keras.models.Sequential()\n    \n#     if Cv_Boolean == 1:\n#         model.add(keras.layers.Conv1D(filters=30, kernel_size=int(n_steps/5), strides=int(n_steps/10), padding='valid', input_shape=[None, input_length]))\n#         model.add(keras.layers.BatchNormalization() )\n#         model.add(keras.layers.GRU(64, return_sequences=True) )\n#         model.add( keras.layers.LayerNormalization() )\n#     else:\n#         model.add(keras.layers.GRU(64, return_sequences=True, input_shape=[None, input_length]))\n#         model.add( keras.layers.LayerNormalization() )\n        \n    hp_unit = hp.Choice('units', [4, 8, 16, 32]) \n    \n    num_fc_layers_min  = 1\n    num_fc_layers_max  = 3\n    \n    dropout_min  =  0\n    dropout_max  =  0.4\n    dropout_step =  0.2\n        \n    for i in range( hp.Int('num_fc_layers',min_value=num_fc_layers_min,max_value=num_fc_layers_max) ):\n        model.add( GRU( hp_unit, return_sequences=True) )\n        model.add( Dropout( hp.Float('dropout_'+str(i+1),min_value=dropout_min,max_value=dropout_max,step=dropout_step) ) )\n        model.add( keras.layers.LayerNormalization() )\n    \n        model.add(keras.layers.GRU(hp_unit, return_sequences=True))\n        model.add(keras.layers.LayerNormalization() )\n        model.add(keras.layers.Dense(pd_raw_Y.shape[1]))\n        \n    model.compile(\n        optimizer=keras.optimizers.Adam(\n        # 학습률은 자주 쓰이는 0.01, 0.001, 0.0001 3개의 값 중 탐색\n            hp.Choice('learning_rate',\n                      values=[1e-2, 1e-3])),\n        loss='mse',\n        metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-07-10T23:53:00.188908Z","iopub.execute_input":"2022-07-10T23:53:00.189152Z","iopub.status.idle":"2022-07-10T23:53:00.202349Z","shell.execute_reply.started":"2022-07-10T23:53:00.18913Z","shell.execute_reply":"2022-07-10T23:53:00.201617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner = kt.Hyperband(\n        model_builder, # HyperModel\n        objective ='val_loss', #  최적화할 하이퍼모델\n        max_epochs = 20, # 각 모델별 학습 회수\n        factor = 3,    # 한 번에 훈련할 모델 수 결정 변수\n        directory ='temp', # 사용된 parameter 저장할 폴더\n        project_name ='helloworld') # 사용된 parameter 저장할 폴더","metadata":{"execution":{"iopub.status.busy":"2022-07-10T23:53:00.203802Z","iopub.execute_input":"2022-07-10T23:53:00.204419Z","iopub.status.idle":"2022-07-10T23:53:02.580337Z","shell.execute_reply.started":"2022-07-10T23:53:00.204357Z","shell.execute_reply":"2022-07-10T23:53:02.57959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search_space_summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T23:53:02.584801Z","iopub.execute_input":"2022-07-10T23:53:02.585069Z","iopub.status.idle":"2022-07-10T23:53:02.590175Z","shell.execute_reply.started":"2022-07-10T23:53:02.585043Z","shell.execute_reply":"2022-07-10T23:53:02.589047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuner 학습\ntuner.search(Train_X, Train_Y,\n             epochs=30,\n             validation_data=(Valid_X, Valid_X), callbacks = [ClearTrainingOutput()])\n\n# Get the optimal hyperparameters\nbest_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n\n# 최고의 모델을 출력\nmodels = tuner.get_best_models(num_models=3)\n# 혹은 결과 출력\ntuner.results_summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T23:53:02.591598Z","iopub.execute_input":"2022-07-10T23:53:02.591931Z","iopub.status.idle":"2022-07-11T02:03:10.301677Z","shell.execute_reply.started":"2022-07-10T23:53:02.591895Z","shell.execute_reply":"2022-07-11T02:03:10.300861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.results_summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T02:03:10.302994Z","iopub.execute_input":"2022-07-11T02:03:10.303492Z","iopub.status.idle":"2022-07-11T02:03:10.311718Z","shell.execute_reply.started":"2022-07-11T02:03:10.303455Z","shell.execute_reply":"2022-07-11T02:03:10.310876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raise SystemExit(\"Exit from script\")\nsys.exit(\"Exit from script\")","metadata":{"execution":{"iopub.status.busy":"2022-07-11T02:03:10.313314Z","iopub.execute_input":"2022-07-11T02:03:10.313845Z","iopub.status.idle":"2022-07-11T02:03:10.321537Z","shell.execute_reply.started":"2022-07-11T02:03:10.31381Z","shell.execute_reply":"2022-07-11T02:03:10.320209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = tuner.hypermodel.build(best_hps)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T02:03:10.32301Z","iopub.status.idle":"2022-07-11T02:03:10.323541Z","shell.execute_reply.started":"2022-07-11T02:03:10.323308Z","shell.execute_reply":"2022-07-11T02:03:10.323332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For 1D-CNN Keras HyperParameter Tuning","metadata":{}},{"cell_type":"code","source":"def cnn_model_builder(hp):\n    model = keras.models.Sequential()\n    \n    hp_filter = hp.Choice('filters', values = [10, 30, 60])\n    hp_kernel = hp.Choice('kernel_size', values = [5, 20, 40, 80])\n    hp_stride = hp.Choice('strides', values = [5, 20, 40, 80])\n\n    model.add(keras.layers.Conv1D(filters = hp_filter, kernel_size = hp_kernel, strides = hp_stride, padding='valid', input_shape=[None, input_length]))\n    model.add(keras.layers.GRU(64, return_sequences=True))\n    model.add(keras.layers.LayerNormalization() )\n\n    model.add(keras.layers.GRU(32, return_sequences=True))\n    model.add(keras.layers.LayerNormalization() )\n    model.add(keras.layers.Dense(pd_raw_Y.shape[1]))\n        \n    model.compile(optimizer=keras.optimizers.Adam(0.001),loss='mse',metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:09:16.068488Z","iopub.execute_input":"2022-07-12T09:09:16.068893Z","iopub.status.idle":"2022-07-12T09:09:16.077248Z","shell.execute_reply.started":"2022-07-12T09:09:16.068863Z","shell.execute_reply":"2022-07-12T09:09:16.076070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner_cnn = kt.Hyperband(\n        cnn_model_builder, # HyperModel\n        objective ='val_loss', #  최적화할 하이퍼모델\n        max_epochs = 30, # 각 모델별 학습 회수\n        factor = 3,    # 한 번에 훈련할 모델 수 결정 변수\n        directory ='temp', # 사용된 parameter 저장할 폴더\n        project_name ='helloworld') # 사용된 parameter 저장할 폴더","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:09:16.095624Z","iopub.execute_input":"2022-07-12T09:09:16.096510Z","iopub.status.idle":"2022-07-12T09:09:16.755611Z","shell.execute_reply.started":"2022-07-12T09:09:16.096452Z","shell.execute_reply":"2022-07-12T09:09:16.754620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner_cnn.search_space_summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:09:16.757076Z","iopub.execute_input":"2022-07-12T09:09:16.757436Z","iopub.status.idle":"2022-07-12T09:09:16.762894Z","shell.execute_reply.started":"2022-07-12T09:09:16.757403Z","shell.execute_reply":"2022-07-12T09:09:16.761847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuner 학습\ntuner_cnn.search(Train_X, Train_Y,\n             epochs=20,\n             validation_data=(Valid_X, Valid_Y), callbacks = [ClearTrainingOutput()])\n\n# Get the optimal hyperparameters\nbest_hps = tuner_cnn.get_best_hyperparameters(num_trials = 1)[0]\n\n# 최고의 모델을 출력\nmodels = tuner_cnn.get_best_models(num_models=3)\n# 혹은 결과 출력\ntuner_cnn.results_summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:09:16.764151Z","iopub.execute_input":"2022-07-12T09:09:16.764771Z","iopub.status.idle":"2022-07-12T11:48:10.857703Z","shell.execute_reply.started":"2022-07-12T09:09:16.764738Z","shell.execute_reply":"2022-07-12T11:48:10.855595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raise SystemExit(\"Exit from script\")\nsys.exit(\"Exit from script\")","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:48:10.859066Z","iopub.status.idle":"2022-07-12T11:48:10.859469Z","shell.execute_reply.started":"2022-07-12T11:48:10.859277Z","shell.execute_reply":"2022-07-12T11:48:10.859296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Machine Learning HP Tuning","metadata":{}},{"cell_type":"markdown","source":"### XGboost","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n\n    params = {\n        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 10),\n        \"learning_rate\": trial.suggest_float('learning_rate', 0.0001, 0.1, log=True),\n        'n_estimators': trial.suggest_int(\"n_estimators\", 100, 1000, log=True),\n        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-2, 1),\n        'gamma': trial.suggest_float('gamma', 0.1, 1.0, log=True),\n    }\n    \n    X_train, X_valid, y_train, y_valid = train_test_split(pd_raw_X, pd_raw_Y.iloc[:,4], test_size=0.3, random_state=11, shuffle=True)\n    \n    model = XGBRegressor(**params, random_state=42)\n    model.fit(X_train,y_train,eval_set=[(X_valid, y_valid)],early_stopping_rounds=100,verbose=False)\n\n    preds = model.predict(X_valid)\n    accuracy = mean_squared_error(y_valid, preds)\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:48:10.860747Z","iopub.status.idle":"2022-07-12T11:48:10.861231Z","shell.execute_reply.started":"2022-07-12T11:48:10.861021Z","shell.execute_reply":"2022-07-12T11:48:10.861049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=50, show_progress_bar=True)\n\nprint(\"Number of finished trials: \", len(study.trials))\nprint(\"Best trial:\")\n\ntrial = study.best_trial\n\nprint(\"Accuracy: {}\".format(trial.value))\nprint(\"Best hyperparameters: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\n\n#clf = xgb.XGBClassifier(**study.best_params, random_state = 1234, use_label_encoder = False)\n#clf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:48:10.862858Z","iopub.status.idle":"2022-07-12T11:48:10.863370Z","shell.execute_reply.started":"2022-07-12T11:48:10.863117Z","shell.execute_reply":"2022-07-12T11:48:10.863143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Randomforest","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n\n    params = {\n        \"max_depth\": trial.suggest_int(\"max_depth\", 10, 1000, log = True),\n        \"max_leaf_nodes\": trial.suggest_int('max_leaf_nodes', 10, 1000, log = True),\n        'n_estimators': trial.suggest_int(\"n_estimators\", 100, 1000, log = True),\n    }\n        \n    X_train, X_valid, y_train, y_valid = train_test_split(pd_raw_X, pd_raw_Y.iloc[:,4], test_size=0.3, random_state=11, shuffle=True)\n    \n    model = RandomForestRegressor(**params, random_state=42)\n    model.fit(X_train, y_train)\n\n    preds = model.predict(X_valid)\n    accuracy = mean_squared_error(y_valid, preds)\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:48:10.864645Z","iopub.status.idle":"2022-07-12T11:48:10.865164Z","shell.execute_reply.started":"2022-07-12T11:48:10.864905Z","shell.execute_reply":"2022-07-12T11:48:10.864930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=20, show_progress_bar=True)\n\nprint(\"Number of finished trials: \", len(study.trials))\nprint(\"Best trial:\")\n\ntrial = study.best_trial\n\nprint(\"Accuracy: {}\".format(trial.value))\nprint(\"Best hyperparameters: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:48:10.866507Z","iopub.status.idle":"2022-07-12T11:48:10.867044Z","shell.execute_reply.started":"2022-07-12T11:48:10.866792Z","shell.execute_reply":"2022-07-12T11:48:10.866818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SVR","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n\n    params = {\n       'C': trial.suggest_float(\"C\",0.1,1000.0,log=True),\n       'gamma': trial.suggest_float(\"gamma\",0.01,100.0,log=True),\n       'epsilon': trial.suggest_float(\"epsilon\",0.01,100.0,log=True)\n    }\n        \n    X_train, X_valid, y_train, y_valid = train_test_split(pd_raw_X, pd_raw_Y.iloc[:,0], test_size=0.3, random_state=11, shuffle=True)\n    \n    model = SVR(**params, kernel='rbf')\n    model.fit(X_train, y_train)\n\n    preds = model.predict(X_valid)\n    accuracy = mean_squared_error(y_valid, preds)\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:48:10.869462Z","iopub.status.idle":"2022-07-12T11:48:10.870154Z","shell.execute_reply.started":"2022-07-12T11:48:10.869882Z","shell.execute_reply":"2022-07-12T11:48:10.869910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=30, show_progress_bar=True)\n\nprint(\"Number of finished trials: \", len(study.trials))\nprint(\"Best trial:\")\n\ntrial = study.best_trial\n\nprint(\"Accuracy: {}\".format(trial.value))\nprint(\"Best hyperparameters: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\n\n#clf = xgb.XGBClassifier(**study.best_params, random_state = 1234, use_label_encoder = False)\n#clf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:48:10.871941Z","iopub.status.idle":"2022-07-12T11:48:10.872461Z","shell.execute_reply.started":"2022-07-12T11:48:10.872209Z","shell.execute_reply":"2022-07-12T11:48:10.872234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n\n    params = {\n       'C': trial.suggest_float(\"C\",0.1,1000.0,log=True),\n       'gamma': trial.suggest_float(\"gamma\",0.01,100.0,log=True),\n       'epsilon': trial.suggest_float(\"epsilon\",0.01,100.0,log=True)\n    }\n        \n    X_train, X_valid, y_train, y_valid = train_test_split(pd_raw_X, pd_raw_Y.iloc[:,2], test_size=0.3, random_state=11, shuffle=True)\n    \n    model = SVR(**params, kernel='rbf')\n    model.fit(X_train, y_train)\n\n    preds = model.predict(X_valid)\n    accuracy = mean_squared_error(y_valid, preds)\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:48:10.874055Z","iopub.status.idle":"2022-07-12T11:48:10.874588Z","shell.execute_reply.started":"2022-07-12T11:48:10.874316Z","shell.execute_reply":"2022-07-12T11:48:10.874344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=20, show_progress_bar=True)\n\nprint(\"Number of finished trials: \", len(study.trials))\nprint(\"Best trial:\")\n\ntrial = study.best_trial\n\nprint(\"Accuracy: {}\".format(trial.value))\nprint(\"Best hyperparameters: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:48:10.876119Z","iopub.status.idle":"2022-07-12T11:48:10.876647Z","shell.execute_reply.started":"2022-07-12T11:48:10.876375Z","shell.execute_reply":"2022-07-12T11:48:10.876401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n\n    params = {\n       'C': trial.suggest_float(\"C\",0.1,1000.0,log=True),\n       'gamma': trial.suggest_float(\"gamma\",0.01,100.0,log=True),\n       'epsilon': trial.suggest_float(\"epsilon\",0.01,100.0,log=True)\n    }\n        \n    X_train, X_valid, y_train, y_valid = train_test_split(pd_raw_X, pd_raw_Y.iloc[:,4], test_size=0.3, random_state=11, shuffle=True)\n    \n    model = SVR(**params, kernel='rbf')\n    model.fit(X_train, y_train)\n\n    preds = model.predict(X_valid)\n    accuracy = mean_squared_error(y_valid, preds)\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:48:10.878012Z","iopub.status.idle":"2022-07-12T11:48:10.878381Z","shell.execute_reply.started":"2022-07-12T11:48:10.878218Z","shell.execute_reply":"2022-07-12T11:48:10.878237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=20, show_progress_bar=True)\n\nprint(\"Number of finished trials: \", len(study.trials))\nprint(\"Best trial:\")\n\ntrial = study.best_trial\n\nprint(\"Accuracy: {}\".format(trial.value))\nprint(\"Best hyperparameters: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:48:10.879396Z","iopub.status.idle":"2022-07-12T11:48:10.879771Z","shell.execute_reply.started":"2022-07-12T11:48:10.879598Z","shell.execute_reply":"2022-07-12T11:48:10.879620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Time Gradient","metadata":{}},{"cell_type":"code","source":"def test_linear_regression2(pd_X, pd_Y, x_column_names, y_column_names, time=0, group_num=5):\n    \"\"\"\n    어느 시간대의 input이 각 target에 얼마나 중요한지 판단하는 함수\n\n    Parameters\n    ----------\n    X : pandas.DataFrame(,5)\n    전체 X 데이터\n\n    Y : pandas.DataFrame(,5)\n    전체 Y 데이터\n\n    x_column_names : list\n    X데이터를 만들때 column의 이름들    \n\n    y_columns_names : list\n    Y데이터를 만들떄 column의 이름들\n\n    time : int\n    Y데이터의 양시점 coef의 중요도를 보기위한 int\n    주어진 int분 만큼의 앞 뒤 X데이터 포함.\n    가능한 input : 10, 20, 30, 60, 120\n\n    group_num : int\n    앞 뒤 몇개의 그룹을 넣어서 linear regression을 사용하는지에 대한 변수\n\n\n    Returns\n    ----------\n    after_X_2d\n    linear regression을 하기 위해 전 처리했던 X의 DataFrame 변수.\n    \n    after_Y_2d\n    linear regression을 하기 위해 전 처리했던 Y의 DataFrame 변수.\n    \n    table_dict\n    linear regression후 결과를 정리한 변수\n    \n    t_result_dict\n    linear regression후 각 Y에 대해 X의 T-value를 정리한 변수\n    \n    f_result_dict\n    linear regression후 각 Y에 대해 X의 coef를 정리한 변수\n    \"\"\"\n    # 원하는 분만큼 group_size를 늘리기 위한 변수.\n    multiple = int(time//10)\n\n    # mean을 계산하기 위한 group_size. 120은 120초를 의미함.\n    group_size = multiple * int(600/group_num)\n\n    np_X = pd_X.values\n    np_Y = pd_Y.values\n\n    # 1. group_size만큼 묶은 후 평균으로 새로운 ndarray를 만듦.\n\n    new_X_mu = np.zeros((int(np_X.shape[0]/group_size), np_X.shape[1]))\n    new_Y = np.zeros((int(np_Y.shape[0]/group_size), np_Y.shape[1]))\n\n    for idx in range(new_X_mu.shape[0]):\n        new_X_mu[idx, :] = np_X[idx *\n                                group_size: (idx+1)*group_size].mean(axis=0)\n        new_Y[idx, :] = np_Y[(idx+1)*group_size-1: (idx+1)\n                             * group_size].reshape(-1)\n\n    # 2. 주어진  time만큼의 앞 뒤 X데이터 n그룹 만큼. default는 5그룹\n\n    X_2d = np.zeros(\n        (new_X_mu.shape[0]-2*group_num+1, new_X_mu.shape[1]*2*group_num))\n\n    for idx in range(new_X_mu.shape[0]-2*group_num+1):\n        X_2d[idx, ] = np.reshape(\n            new_X_mu[idx:idx+2*group_num, :], (1, new_X_mu.shape[1]*2*group_num))\n\n    Y_2d = new_Y[group_num-1:-group_num, :].copy()\n\n    # 3. X, Y를 이용하여 beta를 계산한 후 검정 과정\n\n    table_dict = {}\n\n    batch_size = X_2d.shape[0]\n    Y_dim = Y_2d.shape[1]\n\n#     print(f'현재 분석은 앞 뒤 {time}분에 대한 분석입니다.')\n#     print(f'{group_num}개 의 앞 {time}분, {group_num}개의 뒤 {time}분')\n    X_2d_table = pd.DataFrame(X_2d, columns=[f'{x}_{i}_{time}min' for i in range(\n        1, group_num*2+1) for x in x_column_names])\n    Y_2d_table = pd.DataFrame(Y_2d, columns=y_column_names)\n\n    for idx in range(Y_dim):\n        reg = LinearRegression().fit(X_2d, Y_2d[:, idx])\n        beta_hat = reg.coef_\n        y_hat = X_2d@np.array(beta_hat)\n        mse = np.sum((Y_2d[:, idx]-y_hat)**2)/(batch_size-beta_hat.shape[0])\n        variance_of_beta_hat = np.linalg.inv(X_2d.T@X_2d)*mse\n        se = np.sqrt(np.diag(variance_of_beta_hat))\n\n        p_val = []\n        t_val = []\n        for i in range(beta_hat.shape[0]):\n            p_temp = 2 * \\\n                (1 - t.cdf(abs(beta_hat[i]/se[i]),\n                 batch_size-beta_hat.shape[0]))\n            p_val.append(round(float(p_temp), 3))\n            t_temp = abs(beta_hat[i]/se[i])\n            t_val.append(round(float(t_temp), 3))\n\n        table = pd.DataFrame()\n        table['Variable'] = [f'{x}_{i}_{time}min' for i in range(\n            1, group_num*2+1) for x in x_column_names]\n        table['coef'] = beta_hat\n        table['S.E'] = se\n        table['p-value'] = p_val\n        table['t-value'] = t_val\n        table.loc[(table['p-value'] < 0.05) &\n                  (table['p-value'] >= 0.01), 'star'] = '*'\n        table.loc[(table['p-value'] < 0.01) &\n                  (table['p-value'] >= 0.001), 'star'] = '**'\n        table.loc[(table['p-value'] < 0.001), 'star'] = '***'\n\n        table_dict['{0}'.format(y_column_names[idx])] = table\n\n    # 4. 계수 및  t-value의 시각화를 위한 부분.\n    t_result_dict = {}\n    f_result_dict = {}\n    \n    for target in table_dict.keys():\n        temp_table = pd.DataFrame()\n        temp_table2 = pd.DataFrame()\n        for X in x_column_names:\n            temp = table_dict[f'{target}'].drop(\n                columns=['coef', 'S.E', 'p-value', 'star']).T\n            temp.columns = table_dict[f'{target}']['Variable']\n            temp = temp.drop(index=['Variable'])\n            temp_table[f'{X}'] = temp.filter(like=f'{X}').values.reshape(-1)\n            temp_table.index = [f'{int(group_size*(x+1))}s ~ {int(group_size*x)}s' for x in reversed(range(\n                0, group_num))]+[f'{int(group_size*x)}s ~ {int(group_size*(x+1))}s' for x in range(0, group_num)]\n\n            temp_table = temp_table.astype('float')\n\n            temp2 = table_dict[f'{target}'].drop(\n                columns=['t-value', 'S.E', 'p-value', 'star']).T\n            temp2.columns = table_dict[f'{target}']['Variable']\n            temp2 = temp2.drop(index=['Variable'])\n            temp_table2[f'{X}'] = temp2.filter(like=f'{X}').values.reshape(-1)\n            temp_table2.index = [f'{int(group_size*(x+1))}s ~ {int(group_size*x)}s' for x in reversed(range(\n                0, group_num))]+[f'{int(group_size*x)}s ~ {int(group_size*(x+1))}s' for x in range(0, group_num)]\n            temp_table2 = temp_table2.astype('float')\n\n        t_result_dict[f'{target}'] = temp_table\n        sns.set(font=\"Malgun Gothic\")\n        fig, ax = plt.subplots(figsize=(11, 11))\n        ax = sns.heatmap(temp_table, annot=True, annot_kws={\n                         \"size\": 12}, cmap=\"YlGnBu\",fmt = '.1f')\n        plt.title(f'{target} {time}minute front and back t-value', fontsize=12)\n        plt.show()\n\n        f_result_dict[f'{target}'] = temp_table2\n        sns.set(font=\"Malgun Gothic\")\n        fig, ax = plt.subplots(figsize=(11, 11))\n        ax = sns.heatmap(temp_table2, annot=True,\n                         annot_kws={\"size\": 12}, cmap=\"bwr\",fmt = '.1f')\n        plt.title(f'{target} {time}minute front and back coef', fontsize=12)\n        plt.show()\n\n    return X_2d_table, Y_2d_table, table_dict, t_result_dict, f_result_dict","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"after_X_2d, after_Y_2d, table_result, t_result_dict,coef_result_dict  = test_linear_regression2(pd_raw_X, pd_raw_Y, pd_raw_X_columns, pd_raw_Y_columns, time = 60, group_num = 6)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import seaborn as sns\ndef NN(X, y, epoch, out_type, dict_index):\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(4, activation='relu'))\n    model.add(keras.layers.Dense(after_Y_2d.shape[1]))\n    model.compile(loss=\"mse\", optimizer=\"adam\")\n    history = model.fit(after_X_2d, after_Y_2d, epochs=epoch,verbose=0)\n    \n    pd.DataFrame(history.history).loc[:,['loss']].plot(figsize=(8,5))\n    plt.xlabel('Iteration(epoch)')\n    plt.ylabel('Mean Squared Error')\n    plt.grid(True)\n    \n    if out_type == \"max\":\n        htmp = np.max(abs(model.layers[0].get_weights()[0]),axis=1)\n    elif out_type == \"mean\":\n        htmp = np.mean(abs(model.layers[0].get_weights()[0]),axis=1)\n    else:\n        print(\"You can only check max or mean\" )\n    x_axis_labels = ['H1', 'SPD_RPM', 'X_Servo', 'Bed_Mid', 'S4']\n    y_axis_labels = dict_index[after_Y_2d.columns[0]].index\n    fig, ax = plt.subplots(figsize=(10, 10))\n    plt.title('Fully Connected Layer Weights Mean by Feature', fontsize=12)\n    \n    return sns.heatmap(htmp.reshape(-1,pd_raw_X.shape[1]),xticklabels=x_axis_labels,yticklabels=y_axis_labels,annot=True,annot_kws={\"size\": 12}, cmap=\"YlGnBu\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NN(after_X_2d, after_Y_2d, 50, \"mean\",t_result_dict)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}